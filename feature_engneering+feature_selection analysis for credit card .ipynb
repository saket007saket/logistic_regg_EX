{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\SAKET NANDAN\\Documents\\current_excelr_lms\\logistic_regression_assignment\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "card           0\n",
       "reports        0\n",
       "age            0\n",
       "income         0\n",
       "share          0\n",
       "expenditure    0\n",
       "owner          0\n",
       "selfemp        0\n",
       "dependents     0\n",
       "months         0\n",
       "majorcards     0\n",
       "active         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "    data.drop(labels='Unnamed: 0', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some of the encoder can not able to create realtion ship with categorical type target , so here i m using custom fuction to make the \n",
    "#the target as integer \n",
    "#target is labeled as integer then no need to do this transformation \n",
    "\n",
    "def find_category_mappings(df, variable):\n",
    "    return {k: i for i, k in enumerate(df[variable].unique(), 0)}\n",
    "\n",
    "def integer_encode(data,  variable, ordinal_mapping):\n",
    "\n",
    "    data[variable] = data[variable].map(ordinal_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ['card']:\n",
    "    mappings = find_category_mappings(data, variable)\n",
    "    integer_encode(data, variable, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((923, 11), (396, 11))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's divide into train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels='card', axis=1),  # predictors\n",
    "    data['card'],  # target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 categorical variables in training set.\n",
      "\n",
      "The categorical variables are : ['owner', 'selfemp']\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables\n",
    "\n",
    "categorical = [var for var in X_train.columns if X_train[var].dtype =='O']\n",
    "\n",
    "print('There are {} categorical variables in training set.\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 numerical variables in training set.\n",
      "\n",
      "The numerical variables are : ['reports', 'age', 'income', 'share', 'expenditure', 'dependents', 'months', 'majorcards', 'active']\n"
     ]
    }
   ],
   "source": [
    "# find numerical variables\n",
    "\n",
    "numerical = [var for var in X_train.columns if X_train[var].dtype !='O']\n",
    "\n",
    "print('There are {} numerical variables in training set.\\n'.format(len(numerical)))\n",
    "\n",
    "print('The numerical variables are :', numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight of evidence encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.categorical_encoders import WoERatioCategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_enc = WoERatioCategoricalEncoder(\n",
    "    encoding_method = 'woe',\n",
    "    variables=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WoERatioCategoricalEncoder(encoding_method='woe',\n",
       "                           variables=['owner', 'selfemp'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when fitting the transformer, we need to pass the target as well\n",
    "# just like with any Scikit-learn predictor class\n",
    "\n",
    "woe_enc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe = woe_enc.transform(X_train)\n",
    "X_test_woe = woe_enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ordered integer encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.categorical_encoders import OrdinalCategoricalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_enc = OrdinalCategoricalEncoder(\n",
    "    # NOTE that we indicate ordered in the encoding_method, otherwise it assings numbers arbitrarily\n",
    "    encoding_method='ordered',\n",
    "    variables=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalCategoricalEncoder(encoding_method='ordered',\n",
       "                          variables=['owner', 'selfemp'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_enc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ordered = ordinal_enc.transform(X_train)\n",
    "X_test_ordered = ordinal_enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(random_state=44, C=0.01)\n",
    "    logit.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print(\n",
    "        'Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:, 1])))\n",
    "\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print(\n",
    "        'Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.996363155458573\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9956888255898995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAKET NANDAN\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# ordered labels\n",
    "run_logistic(X_train_ordered, X_test_ordered, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9963499305693315\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9956888255898995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAKET NANDAN\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#woe encoding\n",
    "run_logistic(X_train_woe, X_test_woe, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_woe.copy()\n",
    "X_test=X_test_woe.copy()\n",
    "y_train=y_train.copy()\n",
    "y_test=y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep a copy of the dataset with all the variables\n",
    "# to measure the performance of machine learning models\n",
    "# at the end of the notebook\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((923, 11), (396, 11))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before removing constatnt features\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((923, 11), (396, 11))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove constant features\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    " \n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    " \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicated features in the training set\n",
    "duplicated_feat = []\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    if i % 10 == 0:  # this helps me understand how the loop is going\n",
    "        print(i)\n",
    " \n",
    "    col_1 = X_train.columns[i]\n",
    " \n",
    "    for col_2 in X_train.columns[i + 1:]:\n",
    "        if X_train[col_1].equals(X_train[col_2]):\n",
    "            duplicated_feat.append(col_2)\n",
    "            \n",
    "len(duplicated_feat)#no of duplicate features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((923, 11), (396, 11))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicated features\n",
    "X_train.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
    " \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I keep a copy of the dataset except constant and duplicated variables\n",
    "# to measure the performance of machine learning models\n",
    "# at the end of the notebook\n",
    " \n",
    "X_train_basic_filter = X_train.copy()\n",
    "X_test_basic_filter = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  1\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    " \n",
    "corr_features = correlation(X_train, 0.85)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((923, 10), (396, 10))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removed correlated  features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    " \n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a copy of the dataset at  this stage\n",
    "X_train_corr = X_train.copy()\n",
    "X_test_corr = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features using univariate ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find important features using univariate roc-auc\n",
    " \n",
    "# loop to build a tree, make predictions and get the roc-auc\n",
    "# for each feature of the train set\n",
    " \n",
    "roc_values = []\n",
    "for feature in X_train.columns:\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train[feature].fillna(0).to_frame(), y_train)\n",
    "    y_scored = clf.predict_proba(X_test[feature].fillna(0).to_frame())\n",
    "    roc_values.append(roc_auc_score(y_test, y_scored[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a8ab292388>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's add the variable names and order it for clearer visualisation\n",
    "roc_values = pd.Series(roc_values)\n",
    "roc_values.index = X_train.columns\n",
    "roc_values.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by removing features with univariate roc_auc == 0.5\n",
    "# we remove another 30 features\n",
    " \n",
    "selected_feat = roc_values[roc_values>0.5]\n",
    "len(selected_feat), X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features using Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a lasso and select features, make sure to select l1\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2'))\n",
    "sel_.fit(scaler.transform(X_train), y_train)\n",
    " \n",
    "# remove features with zero coefficient from dataset\n",
    "# and parse again as dataframe (output of sklearn is\n",
    "# numpy array)\n",
    "X_train_lasso = pd.DataFrame(sel_.transform(X_train))\n",
    "X_test_lasso = pd.DataFrame(sel_.transform(X_test))\n",
    " \n",
    "# add the columns name\n",
    "X_train_lasso.columns = X_train.columns[(sel_.get_support())]\n",
    "X_test_lasso.columns = X_train.columns[(sel_.get_support())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((923, 2), (396, 2))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lasso.shape, X_test_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build logistic regression and compare performance in train and test set\n",
    " \n",
    "def run_logistic(X_train, X_test, y_train, y_test):\n",
    "    # function to train and test the performance of logistic regression\n",
    "    logit = LogisticRegression(random_state=44)\n",
    "    logit.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = logit.predict_proba(X_train)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    print('Test set')\n",
    "    pred = logit.predict_proba(X_test)\n",
    "    print('Logistic Regression roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9886596574753687\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9800993109819469\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "scaler = StandardScaler().fit(X_train_original)\n",
    " \n",
    "run_logistic(scaler.transform(X_train_original),\n",
    "             scaler.transform(X_test_original),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9886596574753687\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9800993109819469\n"
     ]
    }
   ],
   "source": [
    "# filter methods - basic\n",
    "scaler = StandardScaler().fit(X_train_basic_filter)\n",
    " \n",
    "run_logistic(scaler.transform(X_train_basic_filter),\n",
    "             scaler.transform(X_test_basic_filter),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9851418369371157\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9749028061126295\n"
     ]
    }
   ],
   "source": [
    "# filter methods - correlation\n",
    "scaler = StandardScaler().fit(X_train_corr)\n",
    " \n",
    "run_logistic(scaler.transform(X_train_corr),\n",
    "             scaler.transform(X_test_corr),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9851418369371157\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9749028061126295\n"
     ]
    }
   ],
   "source": [
    "# filter methods - univariate roc-auc\n",
    "scaler = StandardScaler().fit(X_train[selected_feat.index])\n",
    " \n",
    "run_logistic(scaler.transform(X_train[selected_feat.index]),\n",
    "             scaler.transform(X_test_corr[selected_feat.index]),\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Logistic Regression roc-auc: 0.9487436355220523\n",
      "Test set\n",
      "Logistic Regression roc-auc: 0.9342160976173063\n"
     ]
    }
   ],
   "source": [
    "# embedded methods - Lasso\n",
    "run_logistic(X_train_lasso,\n",
    "             X_test_lasso,\n",
    "                  y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reports', 'share'], dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lasso.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
